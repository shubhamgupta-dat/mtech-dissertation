{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 10:04:19.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mCurrent Model used: gpt-4o\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from loguru import logger as LOGGER\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv(\"gpt-4o.env\")\n",
    "LOGGER.info(f\"Current Model used: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_HISTORICAL_DATA = \"../historical_data/all_to_OMOP_Mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Add Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.read_csv(FP_HISTORICAL_DATA).head(268).dropna()\n",
    "\n",
    "\n",
    "def provide_n_examples(n):\n",
    "    \"\"\"Add N Examples to the Prompt\"\"\"\n",
    "    outputs = list(row.to_dict() for _, row in df_history.sample(n).iterrows())\n",
    "    dict_ouptut = {}\n",
    "    for idx, op in enumerate(outputs):\n",
    "        dict_ouptut[f\"example_src_table_{idx+1}\"] = op[\"source_table\"].lower()\n",
    "        dict_ouptut[f\"example_src_column_{idx+1}\"] = op[\"source_column\"].lower()\n",
    "        dict_ouptut[f\"example_trgt_table_{idx+1}\"] = op[\"target_table\"].lower()\n",
    "        dict_ouptut[f\"example_trgt_column_{idx+1}\"] = op[\"target_column\"].lower()\n",
    "    return dict_ouptut\n",
    "\n",
    "\n",
    "def gen_prompt_for_n_shots(n):\n",
    "    input_vars = [\"source_table\", \"source_column\", \"examples\"]\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=input_vars,\n",
    "        template=\"\"\"\n",
    "        You are a healthcare data expert agent who understands the dataware house ETL well and have an understanding on OMOP Common Data Model.\n",
    "        You usually onboard new source tables on OMOP Data Set as you use this data for downstream Analytics and Apps to power your products. \n",
    "        Your job to provide data matching between any unknown source schema and OMOP table column. And you provide your best guess if you do not know the answer using chain of thoughts.\n",
    "\n",
    "        Provide your answer in the following format:\n",
    "        Target:\n",
    "            Table: [OMOP table name]\n",
    "            Column: [OMOP column name]\n",
    "\n",
    "        {examples}\n",
    "\n",
    "        Answer this Matching:\n",
    "            Source: \n",
    "                Table: {source_table}\n",
    "                Column: {source_column}\n",
    "    \"\"\",\n",
    "    )\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "def gen_n_examples(n):\n",
    "    examples = []\n",
    "    dict_output = provide_n_examples(n)\n",
    "    for i in range(1, n + 1):\n",
    "        src_table_key = f\"example_src_table_{i}\"\n",
    "        src_colmn_key = f\"example_src_column_{i}\"\n",
    "        tgt_table_key = f\"example_trgt_table_{i}\"\n",
    "        tgt_colmn_key = f\"example_trgt_column_{i}\"\n",
    "        examples.append(\n",
    "            f\"\"\"\n",
    "        Example {i}:\n",
    "                Source: \n",
    "                    Table: {dict_output[src_table_key]}\n",
    "                    Column: {dict_output[src_colmn_key]}\n",
    "                Target:\n",
    "                    Table: {dict_output[tgt_table_key]}\n",
    "                    Column: {dict_output[tgt_colmn_key]}\n",
    "\n",
    "        \"\"\"\n",
    "        )\n",
    "    examples = \"\\n\".join(examples)\n",
    "    return examples\n",
    "\n",
    "\n",
    "class MatchTarget(BaseModel):\n",
    "    table: str = Field(\n",
    "        description=\"The OMOP table that matches best with source schema table and column combination\"\n",
    "    )\n",
    "    column: str = Field(\n",
    "        description=\"The column corresponding to the OMOP table that matches best with source schema table and column combination\"\n",
    "    )\n",
    "\n",
    "\n",
    "def process_csv(input_file, n_shots, chain):\n",
    "    results = []\n",
    "\n",
    "    reader = pd.read_csv(input_file)\n",
    "    for _, row in tqdm(reader.iterrows()):\n",
    "        source_table = row[\"source_table\"]\n",
    "        source_column = row[\"source_column\"]\n",
    "        examples = gen_n_examples(n_shots)\n",
    "        input_map = {\n",
    "            \"source_table\": source_table,\n",
    "            \"source_column\": source_column,\n",
    "            \"examples\": examples,\n",
    "        }\n",
    "        # Get prediction from the LLM\n",
    "        response = chain.invoke(input_map)\n",
    "        try:\n",
    "            # Parse the response\n",
    "            target_table = response.table\n",
    "            target_column = response.column\n",
    "\n",
    "        except:\n",
    "            target_table = None\n",
    "            target_column = None\n",
    "\n",
    "        # Create the JSON object\n",
    "        result = {\n",
    "            \"source_table\": source_table,\n",
    "            \"source_column\": source_column,\n",
    "            \"target_table_pred\": target_table,\n",
    "            \"target_table_column_pred\": target_column,\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialise Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI language model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "strucutred_llm = llm.with_structured_output(MatchTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 08:28:49.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:28:49.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:25,  1.55it/s]\n",
      "\u001b[32m2024-09-04 08:34:15.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:34:15.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:34:15.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:01,  1.67it/s]\n",
      "\u001b[32m2024-09-04 08:39:16.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:39:16.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:39:16.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:22,  1.56it/s]\n",
      "\u001b[32m2024-09-04 08:44:39.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:44:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:44:39.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:08,  1.63it/s]\n",
      "\u001b[32m2024-09-04 08:49:47.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:49:47.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:49:47.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:08,  1.63it/s]\n",
      "\u001b[32m2024-09-04 08:54:56.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "list_df_ops = list()\n",
    "for n in range(1, 6):\n",
    "    prompt_template = gen_prompt_for_n_shots(n)\n",
    "    LOGGER.info(f\"Chain Initiated || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    # Create the LLMChain\n",
    "    chain = prompt_template | strucutred_llm\n",
    "    LOGGER.info(f\"Execution Started || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    op_results = process_csv(FP_HISTORICAL_DATA, n_shots=n, chain=chain)\n",
    "    LOGGER.info(f\"Execution Completed || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    df_temp = pd.DataFrame(op_results)\n",
    "    df_temp[\"n_shots\"] = n\n",
    "    list_df_ops.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "async def async_generate(chain, inputs):\n",
    "    \"\"\"\n",
    "    Asynchronous task to extract sentiment and summary from a single review.\n",
    "    Parameters\n",
    "    ----------\n",
    "    chain : SequentialChain\n",
    "        The SequentialChain used for sentiment extraction.\n",
    "    inputs : dict\n",
    "        The inputs for the chain.\n",
    "    unique_id : any\n",
    "        The unique identifier for the review.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing the unique identifier, the extracted sentiment and summary, and the cost.\n",
    "    \"\"\"\n",
    "    with get_openai_callback() as cb:\n",
    "        resp = await chain.ainvoke(inputs)\n",
    "    del inputs[\"examples\"]\n",
    "    return resp, inputs, cb.total_cost, cb.prompt_tokens, cb.completion_tokens\n",
    "\n",
    "\n",
    "global_results = []\n",
    "\n",
    "\n",
    "async def generate_concurrently(input_file, n_shots, chain):\n",
    "    \"\"\"\n",
    "    Generates sentiment and summary concurrently for each review in the dataframe.\n",
    "    The extracted sentiments, summaries, and costs are added to the dataframe.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    reader = pd.read_csv(input_file)\n",
    "    for _, row in tqdm(reader.iterrows()):\n",
    "        source_table = row[\"source_table\"]\n",
    "        source_column = row[\"source_column\"]\n",
    "        examples = gen_n_examples(n_shots)\n",
    "        input_map = {\n",
    "            \"source_table\": source_table,\n",
    "            \"source_column\": source_column,\n",
    "            \"examples\": examples,\n",
    "        }\n",
    "        tasks.append(async_generate(chain, input_map))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    global_results.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(global_results):\n",
    "    total_cost = sum([cost for record, input_value, cost, _, _ in global_results])\n",
    "    list_ops = [record.dict() for record, input_value, cost, _, _ in global_results]\n",
    "    list_ips = [input_value for record, input_value, cost, _, _ in global_results]\n",
    "    total_prompt_tokens = sum([tokens for _, _, _, tokens, _ in global_results])\n",
    "    total_completion_tokens = sum([tokens for _, _, _, _, tokens in global_results])\n",
    "    df_temp_ops = pd.DataFrame(list_ops)\n",
    "    df_temp_ops.columns = [\"target_table_pred\", \"target_table_column_pred\"]\n",
    "    df_temp_ips = pd.DataFrame(list_ips)\n",
    "    df_temp = pd.concat([df_temp_ips, df_temp_ops], axis=1)\n",
    "    return df_temp, total_cost, total_prompt_tokens, total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 11:21:24.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:24.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 4117.68it/s]\n",
      "\u001b[32m2024-09-04 11:21:30.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:30.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:30.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $0.785\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:30.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 137072\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:30.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6663\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:35.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:35.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 8030.66it/s]\n",
      "\u001b[32m2024-09-04 11:21:45.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:45.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:45.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $0.883\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:45.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 156599\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:45.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6647\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:50.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:21:50.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 4428.09it/s]\n",
      "\u001b[32m2024-09-04 11:22:30.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:22:30.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:22:30.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $0.978\u001b[0m\n",
      "\u001b[32m2024-09-04 11:22:30.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 176124\u001b[0m\n",
      "\u001b[32m2024-09-04 11:22:30.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6481\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:00.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:00.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 4572.81it/s]\n",
      "\u001b[32m2024-09-04 11:23:10.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:10.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.072\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 195428\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:10.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6352\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:15.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:23:15.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 3525.32it/s]\n",
      "\u001b[32m2024-09-04 11:24:06.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:06.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:06.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.171\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:06.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 214892\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:06.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6415\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:11.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 6-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:11.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 6-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 4085.71it/s]\n",
      "\u001b[32m2024-09-04 11:24:37.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 6-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:37.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 6-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:37.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.267\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:37.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 234377\u001b[0m\n",
      "\u001b[32m2024-09-04 11:24:37.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6313\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:07.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 7-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:07.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 7-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 3458.73it/s]\n",
      "\u001b[32m2024-09-04 11:25:27.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 7-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:27.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 7-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:27.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.363\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:27.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 253515\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:27.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6360\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:32.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 8-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:25:32.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 8-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 3481.09it/s]\n",
      "\u001b[32m2024-09-04 11:26:15.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 8-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:15.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 8-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:15.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.459\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:15.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 272981\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:15.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6289\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:20.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 9-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:20.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 9-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 3304.82it/s]\n",
      "\u001b[32m2024-09-04 11:26:37.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 9-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:37.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 9-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:37.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.557\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:37.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 292417\u001b[0m\n",
      "\u001b[32m2024-09-04 11:26:37.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6361\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:07.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mChain Initiated || 10-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:07.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAsync Execution Started || 10-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [00:00, 2647.91it/s]\n",
      "\u001b[32m2024-09-04 11:27:26.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mAsync Execution Completed || 10-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:26.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mAsync Execution info for 10-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:26.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTotal Cost: $1.655\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:26.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mTotal Prompt Tokens: 311998\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:26.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mTotal Completion Tokens: 6304\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:31.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mOverall Cost: $12.19\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:31.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mOverall Prompt Tokens: 2245403\u001b[0m\n",
      "\u001b[32m2024-09-04 11:27:31.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mOverall Completion Tokens: 64185\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MAX_SHOTS = 10\n",
    "list_df_ops = []\n",
    "overall_tokens_prompt = 0\n",
    "overall_tokens_completion = 0\n",
    "overall_cost = 0\n",
    "for n_shot in range(1, MAX_SHOTS + 1):\n",
    "    prompt_template = gen_prompt_for_n_shots(n_shot)\n",
    "    LOGGER.info(f\"Chain Initiated || {n_shot}-Shot Prompt(s) Matching using LLMs\")\n",
    "    # Create the LLMChain\n",
    "    chain = prompt_template | strucutred_llm\n",
    "    global_results = []\n",
    "    LOGGER.info(\n",
    "        f\"Async Execution Started || {n_shot}-Shot Prompt(s) Matching using LLMs\"\n",
    "    )\n",
    "    await generate_concurrently(FP_HISTORICAL_DATA, n_shot, chain)\n",
    "    LOGGER.info(\n",
    "        f\"Async Execution Completed || {n_shot}-Shot Prompt(s) Matching using LLMs\"\n",
    "    )\n",
    "    df_temp, total_cost, total_prompt_tokens, total_completion_tokens = get_results(\n",
    "        global_results\n",
    "    )\n",
    "    LOGGER.info(f\"Async Execution info for {n_shot}-Shot Prompt(s) Matching using LLMs\")\n",
    "    LOGGER.info(f\"Total Cost: ${round(total_cost,3)}\")\n",
    "    LOGGER.info(f\"Total Prompt Tokens: {round(total_prompt_tokens,3)}\")\n",
    "    LOGGER.info(f\"Total Completion Tokens: {round(total_completion_tokens,3)}\")\n",
    "    df_temp[\"n_shots\"] = n_shot\n",
    "    list_df_ops.append(df_temp)\n",
    "    overall_cost += total_cost\n",
    "    overall_tokens_prompt += total_prompt_tokens\n",
    "    overall_tokens_completion += total_completion_tokens\n",
    "    if n_shot % 3 == 0:\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        time.sleep(5)\n",
    "\n",
    "LOGGER.info(f\"Overall Cost: ${round(overall_cost,3)}\")\n",
    "LOGGER.info(f\"Overall Prompt Tokens: {round(overall_tokens_prompt,3)}\")\n",
    "LOGGER.info(f\"Overall Completion Tokens: {round(overall_tokens_completion,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(list_df_ops)\n",
    "df_results.to_csv(\"few_shot_ops_gpt_4o.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_table</th>\n",
       "      <th>source_column</th>\n",
       "      <th>target_table_pred</th>\n",
       "      <th>target_table_column_pred</th>\n",
       "      <th>n_shots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>SUBJECT_ID</td>\n",
       "      <td>person</td>\n",
       "      <td>person_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>HADM_ID</td>\n",
       "      <td>visit_occurrence</td>\n",
       "      <td>visit_occurrence_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>ADMITTIME</td>\n",
       "      <td>visit_occurrence</td>\n",
       "      <td>visit_start_datetime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>DISCHTIME</td>\n",
       "      <td>visit_occurrence</td>\n",
       "      <td>visit_end_datetime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>DEATHTIME</td>\n",
       "      <td>death</td>\n",
       "      <td>death_datetime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>NDC</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_source_value</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>SPCLT_IND</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>specialty_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>HCCI_HL_CAT</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_type_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>HCCI_DET_CAT</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_type_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>OVER65_FLAG</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>over65_flag</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5030 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_table source_column target_table_pred target_table_column_pred  \\\n",
       "0         ADMISSIONS    SUBJECT_ID            person                person_id   \n",
       "1         ADMISSIONS       HADM_ID  visit_occurrence      visit_occurrence_id   \n",
       "2         ADMISSIONS     ADMITTIME  visit_occurrence     visit_start_datetime   \n",
       "3         ADMISSIONS     DISCHTIME  visit_occurrence       visit_end_datetime   \n",
       "4         ADMISSIONS     DEATHTIME             death           death_datetime   \n",
       "..               ...           ...               ...                      ...   \n",
       "498  Pharmacy Claims           NDC     drug_exposure        drug_source_value   \n",
       "499  Pharmacy Claims     SPCLT_IND     drug_exposure     specialty_concept_id   \n",
       "500  Pharmacy Claims   HCCI_HL_CAT     drug_exposure     drug_type_concept_id   \n",
       "501  Pharmacy Claims  HCCI_DET_CAT     drug_exposure     drug_type_concept_id   \n",
       "502  Pharmacy Claims   OVER65_FLAG     drug_exposure              over65_flag   \n",
       "\n",
       "     n_shots  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "498       10  \n",
       "499       10  \n",
       "500       10  \n",
       "501       10  \n",
       "502       10  \n",
       "\n",
       "[5030 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
