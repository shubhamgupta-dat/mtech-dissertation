{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 07:49:12.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mCurrent Model used: gpt-4o\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from loguru import logger as LOGGER\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv(\"gpt-4o.env\")\n",
    "LOGGER.info(f\"Current Model used: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_HISTORICAL_DATA = \"../historical_data/all_to_OMOP_Mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Add Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.read_csv(FP_HISTORICAL_DATA).head(268).dropna()\n",
    "\n",
    "\n",
    "def provide_n_examples(n):\n",
    "    \"\"\"Add N Examples to the Prompt\"\"\"\n",
    "    outputs = list(row.to_dict() for _, row in df_history.sample(n).iterrows())\n",
    "    dict_ouptut = {}\n",
    "    for idx, op in enumerate(outputs):\n",
    "        dict_ouptut[f\"example_src_table_{idx+1}\"] = op[\"source_table\"].lower()\n",
    "        dict_ouptut[f\"example_src_column_{idx+1}\"] = op[\"source_column\"].lower()\n",
    "        dict_ouptut[f\"example_trgt_table_{idx+1}\"] = op[\"target_table\"].lower()\n",
    "        dict_ouptut[f\"example_trgt_column_{idx+1}\"] = op[\"target_column\"].lower()\n",
    "    return dict_ouptut\n",
    "\n",
    "\n",
    "def gen_prompt_for_n_shots(n):\n",
    "    input_vars = [\"source_table\", \"source_column\", \"examples\"]\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=input_vars,\n",
    "        template=\"\"\"\n",
    "        You are a healthcare data expert agent who understands the dataware house ETL well and have an understanding on OMOP Common Data Model.\n",
    "        You usually onboard new source tables on OMOP Data Set as you use this data for downstream Analytics and Apps to power your products. \n",
    "        Your job to provide data matching between any unknown source schema and OMOP table column. And you provide your best guess if you do not know the answer using chain of thoughts.\n",
    "\n",
    "        Provide your answer in the following format:\n",
    "        Target:\n",
    "            Table: [OMOP table name]\n",
    "            Column: [OMOP column name]\n",
    "\n",
    "        {examples}\n",
    "\n",
    "        Answer this Matching:\n",
    "            Source: \n",
    "                Table: {source_table}\n",
    "                Column: {source_column}\n",
    "    \"\"\",\n",
    "    )\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "def gen_n_examples(n):\n",
    "    examples = []\n",
    "    dict_output = provide_n_examples(n)\n",
    "    for i in range(1, n + 1):\n",
    "        src_table_key = f\"example_src_table_{i}\"\n",
    "        src_colmn_key = f\"example_src_column_{i}\"\n",
    "        tgt_table_key = f\"example_trgt_table_{i}\"\n",
    "        tgt_colmn_key = f\"example_trgt_column_{i}\"\n",
    "        examples.append(\n",
    "            f\"\"\"\n",
    "        Example {i}:\n",
    "                Source: \n",
    "                    Table: {dict_output[src_table_key]}\n",
    "                    Column: {dict_output[src_colmn_key]}\n",
    "                Target:\n",
    "                    Table: {dict_output[tgt_table_key]}\n",
    "                    Column: {dict_output[tgt_colmn_key]}\n",
    "\n",
    "        \"\"\"\n",
    "        )\n",
    "    examples = \"\\n\".join(examples)\n",
    "    return examples\n",
    "\n",
    "\n",
    "class MatchTarget(BaseModel):\n",
    "    table: str = Field(\n",
    "        description=\"The OMOP table that matches best with source schema table and column combination\"\n",
    "    )\n",
    "    column: str = Field(\n",
    "        description=\"The column corresponding to the OMOP table that matches best with source schema table and column combination\"\n",
    "    )\n",
    "\n",
    "\n",
    "def process_csv(input_file, n_shots, chain):\n",
    "    results = []\n",
    "\n",
    "    with open(input_file, \"r\") as csvfile:\n",
    "        reader = pd.read_csv(csvfile)\n",
    "        for _, row in tqdm(reader.iterrows()):\n",
    "            source_table = row[\"source_table\"]\n",
    "            source_column = row[\"source_column\"]\n",
    "            examples = gen_n_examples(n_shots)\n",
    "            input_map = {\n",
    "                \"source_table\": source_table,\n",
    "                \"source_column\": source_column,\n",
    "                \"examples\": examples,\n",
    "            }\n",
    "            # Get prediction from the LLM\n",
    "            response = chain.invoke(input_map)\n",
    "            try:\n",
    "                # Parse the response\n",
    "                target_table = response.table\n",
    "                target_column = response.column\n",
    "\n",
    "            except:\n",
    "                target_table = None\n",
    "                target_column = None\n",
    "\n",
    "            # Create the JSON object\n",
    "            result = {\n",
    "                \"source_table\": source_table,\n",
    "                \"source_column\": source_column,\n",
    "                \"target_table_pred\": target_table,\n",
    "                \"target_table_column_pred\": target_column,\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialise Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI language model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "strucutred_llm = llm.with_structured_output(MatchTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 08:28:49.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:28:49.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:25,  1.55it/s]\n",
      "\u001b[32m2024-09-04 08:34:15.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 1-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:34:15.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:34:15.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:01,  1.67it/s]\n",
      "\u001b[32m2024-09-04 08:39:16.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 2-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:39:16.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:39:16.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:22,  1.56it/s]\n",
      "\u001b[32m2024-09-04 08:44:39.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 3-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:44:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:44:39.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:08,  1.63it/s]\n",
      "\u001b[32m2024-09-04 08:49:47.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 4-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:49:47.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mChain Initiated || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "\u001b[32m2024-09-04 08:49:47.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mExecution Started || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n",
      "503it [05:08,  1.63it/s]\n",
      "\u001b[32m2024-09-04 08:54:56.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mExecution Completed || 5-Shot Prompt(s) Matching using LLMs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "list_df_ops = list()\n",
    "for n in range(1, 11):\n",
    "    prompt_template = gen_prompt_for_n_shots(n)\n",
    "    LOGGER.info(f\"Chain Initiated || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    # Create the LLMChain\n",
    "    chain = prompt_template | strucutred_llm\n",
    "    LOGGER.info(f\"Execution Started || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    op_results = process_csv(FP_HISTORICAL_DATA, n_shots=n, chain=chain)\n",
    "    LOGGER.info(f\"Execution Completed || {n}-Shot Prompt(s) Matching using LLMs\")\n",
    "    df_temp = pd.DataFrame(op_results)\n",
    "    df_temp[\"n_shots\"] = n\n",
    "    list_df_ops.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(list_df_ops)\n",
    "df_results.to_csv(\"few_shot_ops_gpt_4o.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_table</th>\n",
       "      <th>source_column</th>\n",
       "      <th>target_table_pred</th>\n",
       "      <th>target_table_column_pred</th>\n",
       "      <th>n_shots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>SUBJECT_ID</td>\n",
       "      <td>person</td>\n",
       "      <td>person_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>HADM_ID</td>\n",
       "      <td>visit_occurrence</td>\n",
       "      <td>visit_occurrence_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>ADMITTIME</td>\n",
       "      <td>visit_occurrence</td>\n",
       "      <td>visit_start_datetime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>DISCHTIME</td>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>DISCHTIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADMISSIONS</td>\n",
       "      <td>DEATHTIME</td>\n",
       "      <td>visit_detail</td>\n",
       "      <td>visit_detail_end_datetime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>NDC</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_source_value</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>SPCLT_IND</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>specialty_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>HCCI_HL_CAT</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_type_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>HCCI_DET_CAT</td>\n",
       "      <td>drug_exposure</td>\n",
       "      <td>drug_type_concept_id</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Pharmacy Claims</td>\n",
       "      <td>OVER65_FLAG</td>\n",
       "      <td>person</td>\n",
       "      <td>over_65</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5030 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_table source_column target_table_pred  \\\n",
       "0         ADMISSIONS    SUBJECT_ID            person   \n",
       "1         ADMISSIONS       HADM_ID  visit_occurrence   \n",
       "2         ADMISSIONS     ADMITTIME  visit_occurrence   \n",
       "3         ADMISSIONS     DISCHTIME        ADMISSIONS   \n",
       "4         ADMISSIONS     DEATHTIME      visit_detail   \n",
       "..               ...           ...               ...   \n",
       "498  Pharmacy Claims           NDC     drug_exposure   \n",
       "499  Pharmacy Claims     SPCLT_IND     drug_exposure   \n",
       "500  Pharmacy Claims   HCCI_HL_CAT     drug_exposure   \n",
       "501  Pharmacy Claims  HCCI_DET_CAT     drug_exposure   \n",
       "502  Pharmacy Claims   OVER65_FLAG            person   \n",
       "\n",
       "      target_table_column_pred  n_shots  \n",
       "0                    person_id        1  \n",
       "1          visit_occurrence_id        1  \n",
       "2         visit_start_datetime        1  \n",
       "3                    DISCHTIME        1  \n",
       "4    visit_detail_end_datetime        1  \n",
       "..                         ...      ...  \n",
       "498          drug_source_value       10  \n",
       "499       specialty_concept_id       10  \n",
       "500       drug_type_concept_id       10  \n",
       "501       drug_type_concept_id       10  \n",
       "502                    over_65       10  \n",
       "\n",
       "[5030 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
