{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import AzureOpenAI, AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI language model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"source_table\", \"source_column\"],\n",
    "    template=\"\"\"\n",
    "    Given the source healthcare data table and column:\n",
    "    Source Table: {source_table}\n",
    "    Source Column: {source_column}\n",
    "\n",
    "    Please match this to the most appropriate table and column in the OMOP Common Data Model.\n",
    "    Provide your answer in the following format:\n",
    "    Table: [OMOP table name]\n",
    "    Column: [OMOP column name]\n",
    "\n",
    "    If you're unsure, provide your best guess.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Create the LLMChain\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "\n",
    "def process_csv(input_file):\n",
    "    results = []\n",
    "\n",
    "    with open(input_file, \"r\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in tqdm(reader):\n",
    "            source_table = row[\"source_table\"]\n",
    "            source_column = row[\"source_column\"]\n",
    "\n",
    "            # Get prediction from the LLM\n",
    "            response = chain.invoke(\n",
    "                {\"source_table\": source_table, \"source_column\": source_column}\n",
    "            )\n",
    "            try:\n",
    "                # Parse the response\n",
    "                target_table = response.split(\"\\n\")[0].split(\": \")[1]\n",
    "                target_column = response.split(\"\\n\")[1].split(\": \")[1]\n",
    "\n",
    "            except:\n",
    "                target_table = None\n",
    "                target_column = None\n",
    "\n",
    "            # Create the JSON object\n",
    "            result = {\n",
    "                \"source_table\": source_table,\n",
    "                \"source_column\": source_column,\n",
    "                \"target_table_pred\": target_table,\n",
    "                \"target_table_column_pred\": target_column,\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "503it [06:58,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "op_results = process_csv(\"../historical_data/all_to_OMOP_Mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(op_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"zero_shot_ops.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
